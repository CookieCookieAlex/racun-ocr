from fastapi import FastAPI, File, UploadFile
import cv2
import numpy as np
import imutils
import pytesseract
import os
import uuid
import re

app = FastAPI()

DEBUG_DIR = "debug_images"
os.makedirs(DEBUG_DIR, exist_ok=True)

def save_debug_image(image, step):
    filename = os.path.join(DEBUG_DIR, f"{step}.png")
    success = cv2.imwrite(filename, image)
    print(f"Saved {filename}: {success}, shape: {image.shape}")

def sharpen_edge(img):
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    blur = cv2.GaussianBlur(gray, (7, 7), 0)
    kern = cv2.getStructuringElement(cv2.MORPH_RECT, (11, 11))
    dil = cv2.dilate(blur, kern, iterations=2)
    closed = cv2.morphologyEx(dil, cv2.MORPH_CLOSE, kern, iterations=2)
    edged = cv2.Canny(closed, 30, 100)
    return edged

def binarize(edged):
    mean = np.mean(edged)
    _, binary = cv2.threshold(edged, mean, 255, cv2.THRESH_BINARY)
    kern = cv2.getStructuringElement(cv2.MORPH_RECT, (5, 5))
    dilated = cv2.dilate(binary, kern, iterations=2)
    return dilated

def find_receipt_bb(binary, orig):
    cnts = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[0]
    if not cnts:
        raise ValueError("No contours found")

    for cnt in sorted(cnts, key=cv2.contourArea, reverse=True):
        peri = cv2.arcLength(cnt, True)
        approx = cv2.approxPolyDP(cnt, 0.02 * peri, True)

        if len(approx) == 4:
            rect = cv2.minAreaRect(approx)
            box = np.intp(cv2.boxPoints(rect))
            img_box = cv2.drawContours(orig.copy(), [box], 0, (0, 255, 0), 10)
            return cnt, rect, img_box

    raise ValueError("Could not find 4-point contour for receipt")

def order_points(pts):
    rect = np.zeros((4, 2), dtype="float32")
    s = pts.sum(axis=1)
    rect[0] = pts[np.argmin(s)]
    rect[2] = pts[np.argmax(s)]

    diff = np.diff(pts, axis=1)
    rect[1] = pts[np.argmin(diff)]
    rect[3] = pts[np.argmax(diff)]

    return rect

def four_point_crop(img, pts, padding=10):
    rect = order_points(pts)
    (tl, tr, br, bl) = rect

    widthA = np.linalg.norm(br - bl)
    widthB = np.linalg.norm(tr - tl)
    maxWidth = max(int(widthA), int(widthB))

    heightA = np.linalg.norm(tr - br)
    heightB = np.linalg.norm(tl - bl)
    maxHeight = max(int(heightA), int(heightB))

    pad = padding
    tl[0] = max(tl[0] - pad, 0)
    tl[1] = max(tl[1] - pad, 0)
    tr[0] = max(tr[0] + pad, 0)
    tr[1] = max(tr[1] - pad, 0)
    br[0] = max(br[0] + pad, 0)
    br[1] = max(br[1] + pad, 0)
    bl[0] = max(bl[0] - pad, 0)
    bl[1] = max(bl[1] + pad, 0)

    dst = np.array([
        [0, 0],
        [maxWidth - 1 + 2*pad, 0],
        [maxWidth - 1 + 2*pad, maxHeight - 1 + 2*pad],
        [0, maxHeight - 1 + 2*pad]], dtype="float32")

    src = np.array([tl, tr, br, bl], dtype="float32")
    M = cv2.getPerspectiveTransform(src, dst)
    warped = cv2.warpPerspective(img, M, (maxWidth + 2*pad, maxHeight + 2*pad))
    return warped

def enhance_text(img):
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    _, binary = cv2.threshold(gray, 100, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
    return binary

@app.post("/ocr/")
async def ocr_endpoint(file: UploadFile = File(...)):
    uid = str(uuid.uuid4())[:8]
    print(f"[DEBUG] OCR endpoint hit! ID: {uid}")
    print(f"[DEBUG] Current working directory: {os.getcwd()}")

    contents = await file.read()
    npimg = np.frombuffer(contents, np.uint8)
    img = cv2.imdecode(npimg, cv2.IMREAD_COLOR)

    if img is None:
        return {"error": "Failed to load image"}

    save_debug_image(img, "original")

    edged = sharpen_edge(img)
    save_debug_image(edged, "edged")

    bin_img = binarize(edged)
    save_debug_image(bin_img, "binarized")

    try:
        contour, rect, boxed = find_receipt_bb(bin_img, img)
    except ValueError as e:
        return {"error": str(e)}

    save_debug_image(boxed, "contours")

    angle = rect[2]
    if angle < -45:
        angle += 90
    tilted = imutils.rotate_bound(img, -angle)
    save_debug_image(tilted, "tilted")

    box = cv2.boxPoints(rect)
    box = np.array(box, dtype=np.float32)

    (h, w) = img.shape[:2]
    center = (w / 2, h / 2)
    M = cv2.getRotationMatrix2D(center, -angle, 1.0)

    ones = np.ones(shape=(len(box), 1))
    points_ones = np.hstack([box, ones])
    rotated_box = M.dot(points_ones.T).T

    cropped = four_point_crop(tilted, rotated_box, padding=15)
    save_debug_image(cropped, "cropped")

    enhanced = enhance_text(cropped)
    save_debug_image(enhanced, "enhanced")

    txt = pytesseract.image_to_string(enhanced, lang='hrv', config='--psm 1 --oem 3')
    lines = [line.strip() for line in txt.strip().split('\n') if line.strip()]

    return {
        "lines": lines,
        "debug_folder": os.path.abspath(DEBUG_DIR)
    }
